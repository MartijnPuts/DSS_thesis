{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQeiM3CB1b9L",
        "outputId": "ff17499d-c6b3-44ab-a73c-79ca39cb5f08"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(\"D:\\DSS D-schijf\\Thesis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bi2nMJb6fR-J"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyXltv7RdqIt"
      },
      "source": [
        "## Read csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkbGatc-dPWz"
      },
      "outputs": [],
      "source": [
        "#ADAPTED FROM THE rechtspraak_extractor package of Maastricht University \n",
        "\n",
        "import requests, glob, time\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Check whether the API is working or not and return with the response code\n",
        "def check_api(url):\n",
        "    response = requests.get(f\"{url}\")\n",
        "\n",
        "    # Return with the response code\n",
        "    return response.status_code\n",
        "\n",
        "\n",
        "# Reads all the CSV files in a folder and returns the list of files\n",
        "# It also has an optional parameter \"exclude\". By default, it's None. If you want to exclude files having a certain\n",
        "# word in the file name, you may give a value\n",
        "# It also only grabs data if it has rechtspraak in it\n",
        "# As that was causing issues with other csv data present\n",
        "def read_csv(dir_name, exclude=None):\n",
        "    path = dir_name\n",
        "    csv_files = glob.glob(path + \"/*.csv\")\n",
        "    files = []\n",
        "    for i in csv_files:\n",
        "        if exclude is not None:\n",
        "            if exclude not in i and \"rechtspraak\" in i:\n",
        "                files.append(i)\n",
        "        else:\n",
        "            if \"rechtspraak\" in i:\n",
        "                files.append(i)\n",
        "\n",
        "    print(\"Found \" + str(len(files)) + \" CSV file(s)\\n\")\n",
        "    return files\n",
        "\n",
        "\n",
        "# Get total execution time\n",
        "def get_exe_time(start_time):\n",
        "    end_time = time.time()\n",
        "    sec = end_time - start_time\n",
        "    mins = sec // 60\n",
        "    sec = sec % 60\n",
        "    hours = mins // 60\n",
        "    mins = mins % 60\n",
        "    print(\"Total execution time: {0}:{1}:{2}\".format(int(hours), int(mins), round(sec, 2)))\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLgKjxbsdzYn"
      },
      "source": [
        "## Get rechtspraak  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03OQ_rU4d-Rq"
      },
      "outputs": [],
      "source": [
        "#ADAPTED FROM THE rechtspraak_extractor package of Maastricht University\n",
        "\n",
        "# This file is used to get all the Rechtspraak ECLIs from an API.\n",
        "# It takes two required arguments and one optional argument\n",
        "# 1. max - Maximum number of ECLIs to retrieve\n",
        "# 2. starting-date (yyyy-mm-dd) - Start date of ECLI publication\n",
        "# 3. ending-date (yyyy-mm-dd) - It's an optional parameter. If not given, current date will be automatically chosen\n",
        "# File is stored in data/rechtspraak folder\n",
        "\n",
        "import json\n",
        "import xmltodict\n",
        "import os\n",
        "from datetime import date, datetime\n",
        "\n",
        "\n",
        "# Define base URL\n",
        "RECHTSPRAAK_API_BASE_URL = \"https://data.rechtspraak.nl/uitspraken/zoeken?\"\n",
        "\n",
        "\n",
        "def get_data_from_url(url):\n",
        "    res = requests.get(url)\n",
        "    res.raw.decode_content = True\n",
        "\n",
        "    # Convert the XML data to JSON format\n",
        "    xpars = xmltodict.parse(res.text)\n",
        "    json_string = json.dumps(xpars)\n",
        "    json_object = json.loads(json_string)\n",
        "\n",
        "    # Get the JSON object from a specific branch\n",
        "    json_object = json_object['feed']['entry']\n",
        "\n",
        "    return json_object\n",
        "\n",
        "\n",
        "def save_csv(json_object, file_name, save_file):\n",
        "    # Define the dataframe to enter the data\n",
        "    df = pd.DataFrame(columns=['id', 'title', 'summary', 'updated', 'link'])\n",
        "    ecli_id = []\n",
        "    title = []\n",
        "    summary = []\n",
        "    updated = []\n",
        "    link = []\n",
        "\n",
        "    # Iterate over the object and fill the lists\n",
        "    for i in json_object:\n",
        "        ecli_id.append(i['id'])\n",
        "        title.append(i['title']['#text'])\n",
        "        if '#text' in i['summary']:\n",
        "            summary.append(i['summary']['#text'])\n",
        "        else:\n",
        "            summary.append(\"No summary available\")\n",
        "        updated.append(i['updated'])\n",
        "        link.append(i['link']['@href'])\n",
        "\n",
        "    # Save the lists to dataframe\n",
        "    df['id'] = ecli_id\n",
        "    df['title'] = title\n",
        "    df['summary'] = summary\n",
        "    df['updated'] = updated\n",
        "    df['link'] = link\n",
        "\n",
        "    if save_file == 'y':\n",
        "        # Create directory if not exists\n",
        "        Path('data').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Save CSV file\n",
        "        # file_path = os.path.join('data', file_name + '.csv')\n",
        "        df.to_csv('data/' + file_name + '.csv', index=False, encoding='utf8')\n",
        "        print(\"Data saved to CSV file successfully.\")\n",
        "    return df\n",
        "\n",
        "def get_rechtspraak(max_ecli=100, sd='1900-01-01', ed=None, save_file='y', from_value=0, instantie='', rechtsgebied=''):\n",
        "    print(\"Rechtspraak dump downloader API\")\n",
        "\n",
        "    amount = max_ecli\n",
        "    starting_date = sd\n",
        "    save_file = save_file\n",
        "\n",
        "    # If the end date is not entered, the current date is taken\n",
        "    today = date.today()\n",
        "    if ed:\n",
        "        ending_date = ed\n",
        "    else:\n",
        "        ending_date = today.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    # Used to calculate total execution time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Build the URL after getting all the arguments\n",
        "    url = RECHTSPRAAK_API_BASE_URL + 'max=' + str(amount) + '&date=' + starting_date + '&date=' + ending_date + '&from=' +str(from_value)+ '&return=DOC' + '&creator=' + instantie\n",
        "\n",
        "    print(\"Checking the API\")\n",
        "    # Check the working of API\n",
        "    response_code = check_api(url)\n",
        "    if response_code == 200:\n",
        "        print(\"API is working fine!\")\n",
        "        print(\"Getting \" + str(amount) + \" documents from \" + starting_date + \" till \" + ending_date)\n",
        "\n",
        "        json_object = get_data_from_url(url)\n",
        "        print(f\"Found {len(json_object)} cases!\")\n",
        "        if json_object:\n",
        "            # Get current time\n",
        "            current_time = datetime.now().strftime(\"%H-%M-%S\")\n",
        "\n",
        "            # Build file name\n",
        "            file_name = 'rechtspraak_' + starting_date + '_' + ending_date + '_' + current_time\n",
        "\n",
        "\n",
        "            get_exe_time(start_time)\n",
        "\n",
        "            if save_file == 'n':\n",
        "                #global_rs_df = save_csv(json_object, file_name, save_file)\n",
        "                return  json_object #global_rs_df\n",
        "            else:\n",
        "                save_csv(json_object, file_name, save_file)\n",
        "                return\n",
        "    else:\n",
        "        print(f\"URL returned with a {response_code} error code\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifpiEV55d9s5"
      },
      "source": [
        "## Get metadata\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsLKdr1-eDMv"
      },
      "outputs": [],
      "source": [
        "#ADAPTED FROM THE rechtspraak_extractor package of Maastricht University\n",
        "\n",
        "# This file is used for getting the metadata of the ECLIs obtained using rechspraak_api file. This file takes all the\n",
        "# CSV file created by rechspraak_api, picks up ECLIs and links column, and using an API gets the metadata and saves it\n",
        "# in another CSV file with metadata suffix.\n",
        "# This happens in async manner.\n",
        "import pathlib\n",
        "import os\n",
        "import urllib\n",
        "import multiprocessing\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import platform\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "from functools import partial\n",
        "# Define base url\n",
        "RECHTSPRAAK_METADATA_API_BASE_URL = \"http://data.rechtspraak.nl/uitspraken/content?id=\" # old one = \"https://uitspraken.rechtspraak.nl/#!/details?id=\"\n",
        "return_type = \"&return=DOC\"\n",
        "\n",
        "# Define empty lists where we'll store our data temporarily\n",
        "ecli_df = []\n",
        "full_text_df = []\n",
        "creator_df = []\n",
        "date_decision_df = []\n",
        "issued_df = []\n",
        "zaaknummer_df = []\n",
        "type_df = []\n",
        "relations_df = []\n",
        "references_df = []\n",
        "subject_df = []\n",
        "procedure_df = []\n",
        "inhoudsindicatie_df = []\n",
        "hasVersion_df = []\n",
        "\n",
        "threads = []\n",
        "max_workers = 0\n",
        "\n",
        "\n",
        "def get_cores():\n",
        "    # max_workers is the number of concurrent processes supported by your CPU multiplied by 5.\n",
        "    # You can change it as per the computing power.\n",
        "    # Different python versions treat this differently. This is written as per python 3.6.\n",
        "    n_cores = multiprocessing.cpu_count()\n",
        "\n",
        "    global max_workers\n",
        "    max_workers = n_cores-1\n",
        "    # If the main process is computationally intensive: Set to the number of logical CPU cores minus one.\n",
        "\n",
        "    print(f\"Maximum \" + str(max_workers) + \" threads supported by your machine.\")\n",
        "\n",
        "\n",
        "def extract_data_from_xml(url):\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "        xml_file = response.read()\n",
        "        return xml_file\n",
        "\n",
        "\n",
        "\n",
        "def check_if_df_empty(df):\n",
        "    if df.empty:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def get_text_if_exists(el):\n",
        "    try:\n",
        "        return el.text\n",
        "    except:\n",
        "        return ''\n",
        "\n",
        "def update_bar(bar, *args):\n",
        "    bar.update(1)\n",
        "\n",
        "\n",
        "def save_data_when_crashed(ecli):\n",
        "    ecli_df.append(ecli)\n",
        "    full_text_df.append(\"\")\n",
        "    creator_df.append(\"\")\n",
        "    date_decision_df.append(\"\")\n",
        "    issued_df.append(\"\")\n",
        "    zaaknummer_df.append(\"\")\n",
        "    type_df.append(\"\")\n",
        "    relations_df.append(\"\")\n",
        "    references_df.append(\"\")\n",
        "    subject_df.append(\"\")\n",
        "    procedure_df.append(\"\")\n",
        "    inhoudsindicatie_df.append(\"\")\n",
        "    hasVersion_df.append(\"\")\n",
        "def get_data_from_api(ecli_id):\n",
        "    url = RECHTSPRAAK_METADATA_API_BASE_URL + ecli_id + return_type\n",
        "    try:\n",
        "        response_code = check_api(url)\n",
        "    except:\n",
        "        save_data_when_crashed(ecli_id)\n",
        "        return\n",
        "    global ecli_df, full_text_df, creator_df, date_decision_df, issued_df, zaaknummer_df, type_df, \\\n",
        "        relations_df, references_df, subject_df, procedure_df, inhoudsindicatie_df, hasVersion_df\n",
        "    try:\n",
        "        if response_code == 200:\n",
        "            try:\n",
        "                # Extract data from xml\n",
        "                xml_object = extract_data_from_xml(url)\n",
        "                soup = BeautifulSoup(xml_object, features='xml')\n",
        "                # Get the data\n",
        "                creator = get_text_if_exists(soup.find(\"dcterms:creator\"))\n",
        "                date_decision = get_text_if_exists(soup.find(\"dcterms:date\"))\n",
        "                issued = get_text_if_exists(soup.find(\"dcterms:issued\"))\n",
        "                zaaknummer = get_text_if_exists(soup.find(\"psi:zaaknummer\"))\n",
        "                rs_type = get_text_if_exists(soup.find(\"dcterms:type\"))\n",
        "                subject = get_text_if_exists(soup.find(\"dcterms:subject\"))\n",
        "                relation = soup.findAll(\"dcterms:relation\")\n",
        "                relatie = ''\n",
        "                for i in relation:\n",
        "                    # append the string to relation\n",
        "                    text = get_text_if_exists(i)\n",
        "                    if text == '':\n",
        "                        continue\n",
        "                    else:\n",
        "                        relatie += text + \"\\n\"\n",
        "                relations = relatie\n",
        "                reference = soup.findAll(\"dcterms:references\")\n",
        "                ref = ''\n",
        "                for u in reference:\n",
        "                    text = get_text_if_exists(u)\n",
        "                    # append the string to relation\n",
        "                    if text ==\"\":\n",
        "                        continue\n",
        "                    else:\n",
        "                        ref += text + \"\\n\"\n",
        "                references = ref\n",
        "                procedure = get_text_if_exists(soup.find(\"psi:procedure\"))\n",
        "                inhoudsindicatie = get_text_if_exists(soup.find(\"inhoudsindicatie\"))\n",
        "                hasVersion = get_text_if_exists(soup.find(\"dcterms:hasVersion\"))\n",
        "                full_text = get_text_if_exists(soup.find(\"uitspraak\"))\n",
        "\n",
        "                ecli_df.append(ecli_id)\n",
        "                print(ecli_id)\n",
        "                full_text_df.append(full_text)\n",
        "                creator_df.append(creator)\n",
        "                date_decision_df.append(date_decision)\n",
        "                issued_df.append(issued)\n",
        "                zaaknummer_df.append(zaaknummer)\n",
        "                type_df.append(rs_type)\n",
        "                relations_df.append(relations)\n",
        "                references_df.append(references)\n",
        "                subject_df.append(subject)\n",
        "                procedure_df.append(procedure)\n",
        "                inhoudsindicatie_df.append(inhoudsindicatie)\n",
        "                hasVersion_df.append(hasVersion)\n",
        "                del full_text, creator, date_decision, issued, zaaknummer,relations, rs_type,\\\n",
        "                    references, subject,procedure, inhoudsindicatie, hasVersion\n",
        "\n",
        "                urllib.request.urlcleanup()\n",
        "\n",
        "            except Exception as e:\n",
        "                save_data_when_crashed(ecli_id)\n",
        "        else:\n",
        "            save_data_when_crashed(ecli_id)\n",
        "    except Exception as e:\n",
        "        save_data_when_crashed(ecli_id)\n",
        "\n",
        "\n",
        "def get_rechtspraak_metadata(save_file='n', dataframe=None, filename=None):\n",
        "    if dataframe is not None and filename is not None:\n",
        "        print(f\"Please provide either a dataframe or a filename, but not both\")\n",
        "        return False\n",
        "\n",
        "    if dataframe is None and filename is None and save_file == 'n':\n",
        "        print(f\"Please provide at least a dataframe of filename when the save_file is \\\"n\\\"\")\n",
        "        return False\n",
        "\n",
        "    print(\"Rechtspraak metadata API\")\n",
        "\n",
        "    start_time = time.time()  # Get start time\n",
        "\n",
        "    no_of_rows = ''\n",
        "    rs_data = ''\n",
        "    csv_files = 0\n",
        "\n",
        "    # Check if dataframe is provided and is correct\n",
        "    if dataframe is not None:\n",
        "        if 'id' in dataframe and 'link' in dataframe:\n",
        "            rs_data = dataframe\n",
        "            no_of_rows = rs_data.shape[0]\n",
        "        else:\n",
        "            print(\"Dataframe is corrupted or does not contain necessary information to get the metadata.\")\n",
        "            return False\n",
        "\n",
        "    # Check if filename is provided and is correct\n",
        "    if filename is not None:\n",
        "        print(\"Reading \" + filename + \" from data folder\")\n",
        "        file_check = pathlib.Path(\"data/\" + filename)\n",
        "        if file_check.is_file():\n",
        "            print(\"File found. Checking if metadata already exists\")\n",
        "            # Check if metadata already exists\n",
        "            file_check = Path(\"data/\" + filename.split('/')[-1][:len(filename.split('/')[-1]) - 4]\n",
        "                              + \"_metadata.csv\")\n",
        "            if file_check.is_file():\n",
        "                print(\"Metadata for \" + filename.split('/')[-1][:len(filename.split('/')[-1]) - 4] +\n",
        "                      \".csv already exists.\")\n",
        "                return False\n",
        "            else:\n",
        "                rs_data = pd.read_csv('data/' + filename)\n",
        "                if 'id' in rs_data and 'link' in rs_data:\n",
        "                    no_of_rows = rs_data.shape[0]\n",
        "                else:\n",
        "                    print(\"File is corrupted or does not contain necessary information to get the metadata.\")\n",
        "                    return False\n",
        "        else:\n",
        "            print(\"File not found. Please check the file name.\")\n",
        "            return False\n",
        "\n",
        "    get_cores()  # Get number of cores supported by the CPU\n",
        "\n",
        "    if dataframe is None and filename is None and save_file == 'y':\n",
        "        print(\"No dataframe or file name is provided. Getting the metadata of all the files present in the \"\n",
        "              \"data folder\")\n",
        "\n",
        "        print(\"Reading all CSV files in the data folder...\")\n",
        "        csv_files = read_csv('data', \"metadata\")\n",
        "\n",
        "        global ecli_df, full_text_df, creator_df, date_decision_df, issued_df, zaaknummer_df, \\\n",
        "           type_df, relations_df,references_df, subject_df,\\\n",
        "           procedure_df, inhoudsindicatie_df, hasVersion_df\n",
        "        if len(csv_files) > 0 and save_file == 'y':\n",
        "            for f in csv_files:\n",
        "                # Create empty dataframe\n",
        "                rsm_df = pd.DataFrame(columns=['ecli', 'full_text', 'creator', 'date_decision',\n",
        "                                               'issued', 'zaaknummer','type',\"relations\",\n",
        "                                                'references','subject','procedure',\n",
        "                                                'inhoudsindicatie', 'hasVersion'])\n",
        "\n",
        "                temp_file_name = f.split('\\\\')[-1][:len(f.split('\\\\')[-1]) - 4]\n",
        "\n",
        "                # Check if file already exists\n",
        "                file_check = Path(\"data/\" + temp_file_name + \"_metadata.csv\")\n",
        "                if file_check.is_file():\n",
        "                    print(\"Metadata for \" + temp_file_name + \".csv already exists.\")\n",
        "                    continue\n",
        "\n",
        "                df = pd.read_csv(f)\n",
        "                no_of_rows = df.shape[0]\n",
        "                print(\"Getting metadata of \" + str(no_of_rows) + \" ECLIs from \" + temp_file_name + \".csv\")\n",
        "                print(\"Working. Please wait...\")\n",
        "\n",
        "                # Get all ECLIs in a list\n",
        "                ecli_list = list(df.loc[:, 'id'])\n",
        "\n",
        "                # Create a temporary directory to save files\n",
        "                time.sleep(1)\n",
        "                Path('temp_rs_data').mkdir(parents=True, exist_ok=True)\n",
        "                with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "                    for ecli in ecli_list:\n",
        "                        threads.append(executor.submit(get_data_from_api, ecli))\n",
        "\n",
        "                # Delete temporary directory\n",
        "                shutil.rmtree('temp_rs_data')\n",
        "                # executor.shutdown()  # Shutdown the executor\n",
        "\n",
        "                rsm_df['ecli'] = ecli_df\n",
        "                rsm_df['full_text'] = full_text_df\n",
        "                rsm_df['creator'] = creator_df\n",
        "                rsm_df['date_decision'] = date_decision_df\n",
        "                rsm_df['issued'] = issued_df\n",
        "                rsm_df['zaaknummer'] = zaaknummer_df\n",
        "                rsm_df['type'] = type_df\n",
        "                rsm_df['relations'] = relations_df\n",
        "                rsm_df['references'] = references_df\n",
        "                rsm_df['subject'] = subject_df\n",
        "                rsm_df['procedure'] = procedure_df\n",
        "                rsm_df['inhoudsindicatie'] = inhoudsindicatie_df\n",
        "                rsm_df['hasVersion'] = hasVersion_df\n",
        "                addition = rs_data[['id', 'summary']]\n",
        "                rsm_df = rsm_df.merge(addition, how='left', left_on='ecli', right_on='id').drop(['id'], axis=1)\n",
        "                # Create directory if not exists\n",
        "                Path('data').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "                if check_if_df_empty(rsm_df):\n",
        "                    print(\"Metadata not found. Please check the API response; either API is under maintenance, \"\n",
        "                          \"experiencing problems, or has changed. Please try again after some time or contact the \"\n",
        "                          \"administrator.\\n\")\n",
        "                else:\n",
        "                    # Save CSV file\n",
        "                    print(\"Creating CSV file...\")\n",
        "                    rsm_df.to_csv(\"data/\" + temp_file_name + \"_metadata.csv\", index=False, encoding='utf8')\n",
        "                    print(\"CSV file \" + temp_file_name + \"_metadata.csv  successfully created.\\n\")\n",
        "\n",
        "                # Clear the lists for the next file\n",
        "                ecli_df = []\n",
        "                full_text_df = []\n",
        "                creator_df = []\n",
        "                date_decision_df = []\n",
        "                issued_df = []\n",
        "                zaaknummer_df = []\n",
        "                type_df = []\n",
        "                relations_df = []\n",
        "                references_df = []\n",
        "                subject_df = []\n",
        "                procedure_df = []\n",
        "                inhoudsindicatie_df = []\n",
        "                hasVersion_df = []\n",
        "                ecli_list = []\n",
        "                del rsm_df\n",
        "            return True\n",
        "\n",
        "    if rs_data is not None:\n",
        "        rsm_df = pd.DataFrame(columns=['ecli', 'full_text', 'creator', 'date_decision', 'issued',\n",
        "                                       'zaaknummer','type','relations','references', 'subject', 'procedure',\n",
        "                                        'inhoudsindicatie','hasVersion'])\n",
        "\n",
        "        print(\"Getting metadata of \" + str(no_of_rows) + \" ECLIs\")\n",
        "        print(\"Working. Please wait...\")\n",
        "        # Get all ECLIs in a list\n",
        "        ecli_list = list(rs_data.loc[:, 'id'])\n",
        "\n",
        "        # Create a temporary directory to save files\n",
        "        Path('temp_rs_data').mkdir(parents=True, exist_ok=True)\n",
        "        time.sleep(1)\n",
        "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "            bar = tqdm(total=len(ecli_list), colour=\"GREEN\",position=0, leave=True, miniters=int(len(ecli_list)/100),\n",
        "                       maxinterval=10000)\n",
        "            for ecli in ecli_list:\n",
        "                threads.append(executor.submit(get_data_from_api, ecli))\n",
        "            for t in threads:\n",
        "                t.add_done_callback(partial(update_bar,bar))\n",
        "        # Delete temporary directory\n",
        "        shutil.rmtree('temp_rs_data')\n",
        "         # to finish unfinished?\n",
        "        # global ecli_df, full_text_df, creator_df, date_decision_df, issued_df, zaaknummer_df, \\\n",
        "        #    relations_df, subject_df, procedure_df, inhoudsindicatie_df, hasVersion_df\n",
        "\n",
        "        rsm_df['ecli'] = ecli_df\n",
        "        rsm_df['full_text'] = full_text_df\n",
        "        rsm_df['creator'] = creator_df\n",
        "        rsm_df['date_decision'] = date_decision_df\n",
        "        rsm_df['issued'] = issued_df\n",
        "        rsm_df['zaaknummer'] = zaaknummer_df\n",
        "        rsm_df['type'] = type_df\n",
        "        rsm_df['relations'] = relations_df\n",
        "        rsm_df['references'] = references_df\n",
        "        rsm_df['subject'] = subject_df\n",
        "        rsm_df['procedure'] = procedure_df\n",
        "        rsm_df['inhoudsindicatie'] = inhoudsindicatie_df\n",
        "        rsm_df['hasVersion'] = hasVersion_df\n",
        "        addition = rs_data[['id','summary']]\n",
        "        rsm_df = rsm_df.merge(addition, how='left', left_on='ecli', right_on='id').drop(['id'], axis=1)\n",
        "        if save_file == 'y':\n",
        "            if filename is None or filename == '':\n",
        "                filename = \"custom_rechtspraak_\" + datetime.now().strftime(\"%H-%M-%S\") + \".csv\"\n",
        "            # Create directory if not exists\n",
        "            Path('data').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "            if check_if_df_empty(rsm_df):\n",
        "                print(\"Metadata not found. Please check the API response; either API is under maintenance, \"\n",
        "                      \"experiencing problems, or has changed. Please try again after some time or contact the \"\n",
        "                      \"administrator.\\n\")\n",
        "            else:\n",
        "                # Save CSV file\n",
        "                print(\"Creating CSV file...\")\n",
        "                rsm_df.to_csv(\"data/\" + filename.split('/')[-1][:len(filename.split('/')[-1]) - 4] + \"_metadata.csv\",\n",
        "                              index=False, encoding='utf8')\n",
        "                print(\"CSV file \" + filename.split('/')[-1][:len(filename.split('/')[-1]) - 4] + \"_metadata.csv\" +\n",
        "                      \" successfully created.\\n\")\n",
        "\n",
        "        # Clear the lists for the next file\n",
        "        ecli_df = []\n",
        "        full_text_df = []\n",
        "        creator_df = []\n",
        "        date_decision_df = []\n",
        "        issued_df = []\n",
        "        zaaknummer_df = []\n",
        "        type_df = []\n",
        "        relations_df = []\n",
        "        references_df = []\n",
        "        subject_df = []\n",
        "        procedure_df = []\n",
        "        inhoudsindicatie_df = []\n",
        "        hasVersion_df = []\n",
        "        ecli_list = []\n",
        "\n",
        "        get_exe_time(start_time)\n",
        "\n",
        "        if save_file == 'n':\n",
        "            return rsm_df\n",
        "\n",
        "        return True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxC9s16deJXU"
      },
      "source": [
        "## Get citations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDFgFqXWed77"
      },
      "outputs": [],
      "source": [
        "#ADAPTED FROM THE rechtspraak_citation_extractor package of Maastricht University\n",
        "\n",
        "import requests\n",
        "from lxml import etree\n",
        "import urllib.request\n",
        "import rdflib\n",
        "import threading\n",
        "import json\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from requests.auth import HTTPBasicAuth\n",
        "from tqdm import tqdm\n",
        "load_dotenv()\n",
        "\n",
        "LIDO_ENDPOINT = \"http://linkeddata.overheid.nl/service/get-links\"\n",
        "\n",
        "target_ecli = 'target_ecli'\n",
        "label = 'label'\n",
        "type = 'type'\n",
        "ecli = 'ecli'\n",
        "case_citations_fieldnames = [target_ecli, label, type]\n",
        "legislation_citations_fieldnames = ['legal_provision_url_lido', 'legal_provision_url', 'legal_provision']\n",
        "\n",
        "\n",
        "def remove_spaces_from_ecli(ecli):\n",
        "    return ecli.replace(\" \", \"\")\n",
        "\n",
        "\n",
        "def write_incremental_rows(filename, data):\n",
        "    with open(filename, 'a') as f:\n",
        "        pd.DataFrame(data).to_csv(f, mode='a', header=not f.tell(), index=False)\n",
        "\n",
        "\n",
        "# Code to execute LIDO API call\n",
        "def get_lido_response(url, username, password):\n",
        "    authentication = HTTPBasicAuth(username, password)\n",
        "    response = requests.get(url, auth=authentication)\n",
        "    if response.status_code == 200:\n",
        "        return response.text\n",
        "    else:\n",
        "        raise Exception('LinkedData responded with code {}: {}. {}'.format(response.status_code, response.reason, url))\n",
        "\n",
        "\n",
        "# Extract the ECLI code from the LIDO identifier of the cited case law from the XML response from LIDO API\n",
        "def get_ecli(sub_ref):\n",
        "    return sub_ref.attrib['idref'].split('/')[-1]\n",
        "\n",
        "\n",
        "# Extract the LIDO identifier of the cited legislation from the XML response from LIDO API\n",
        "def get_legislation_identifier(sub_ref):\n",
        "    return sub_ref.attrib['idref']\n",
        "\n",
        "\n",
        "# Find the webpage expressing, in writing, the legislation referred to by the input LIDO identifier\n",
        "def get_legislation_webpage(identifier):\n",
        "    idcomponents = identifier.split(\"/\")\n",
        "    date = idcomponents[len(idcomponents) - 1]\n",
        "    url = identifier\n",
        "    page = urllib.request.urlopen(url)\n",
        "    g = rdflib.Graph()\n",
        "    g.parse(page, format=\"xml\")\n",
        "    article = \"\"\n",
        "    for s, p, o in g:\n",
        "        if str(p) == \"http://purl.org/dc/terms/identifier\":\n",
        "            article = o\n",
        "            if date in str(o):\n",
        "                return o\n",
        "\n",
        "    return article\n",
        "\n",
        "\n",
        "def get_legislation_name(url, username, password):\n",
        "    # turn the response into an xml tree\n",
        "    xml_response = get_lido_response(url, username, password)\n",
        "    xml = etree.fromstring(bytes(xml_response, encoding='utf8'))\n",
        "\n",
        "    pref_label = \"\"\n",
        "    title = \"\"\n",
        "    # RDF main element (root)\n",
        "    for element in xml.iterchildren():\n",
        "        # there is only one child and it is the \"description\" in which the rest of the info is\n",
        "        # go through all the tags (all the info)\n",
        "        for el in element.iterchildren():\n",
        "            # the title (same thing as the preLabel) is the feature we want to be using\n",
        "            if el.tag == \"{http://purl.org/dc/terms/}title\":\n",
        "                title = el.text\n",
        "\n",
        "    return title\n",
        "\n",
        "\n",
        "# Check if outgoing links in the XML response from the LIDO API are of type \"Jurisprudentie\" (case law)\n",
        "def is_case_law(sub_ref):\n",
        "    return sub_ref.attrib['groep'] == 'Jurisprudentie'\n",
        "\n",
        "\n",
        "# Check if outgoing links in the XML response from the LIDO API are of type \"Wet\" (legislation)\n",
        "def is_legislation(sub_ref):\n",
        "    return sub_ref.attrib['groep'] == 'Wet' or sub_ref.attrib['groep'] == 'Artikel'\n",
        "\n",
        "\n",
        "# Extract ECLI code of citation from a lido identifier.\n",
        "# Example of a LIDO identifier \"https://linkeddata.overheid.nl/terms/bwb/id/BWBR0020368/8655654/2016-08-11/2016-08-11\"\n",
        "def get_lido_id(ecli):\n",
        "    return \"http://linkeddata.overheid.nl/terms/jurisprudentie/id/\" + ecli\n",
        "\n",
        "\n",
        "# Method written by Marion\n",
        "\"\"\"\n",
        "These methods are used to write the citations incrementally to the csv file (in case it crashes or times out).\n",
        "It allows us to stop the script whenever we want without loosing our data, and without having to start from the bginning the next time.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Main method to execute LIDO API call on a list of ECLIs from a CSV file and extract the citations of each\n",
        "# Add the implementation of the incremental writing of rows\n",
        "def find_citations_for_cases(dataframe, username, password):\n",
        "    df_eclis = dataframe.reset_index(drop=True)\n",
        "\n",
        "    eclis = list(df_eclis['ecli'].dropna())\n",
        "    total_incoming = []\n",
        "    total_outgoing = []\n",
        "    total_legislations = []\n",
        "\n",
        "    for i, ecli in enumerate(eclis):\n",
        "        case_citations_incoming, case_citations_outgoing, legislation_citations = find_citations_for_case(\n",
        "            remove_spaces_from_ecli(ecli), case_citations_fieldnames, legislation_citations_fieldnames, username,\n",
        "            password)\n",
        "        if case_citations_incoming:\n",
        "            total_incoming.extend(case_citations_incoming)\n",
        "        if case_citations_outgoing:\n",
        "            total_outgoing.extend(case_citations_outgoing)\n",
        "        if legislation_citations:\n",
        "            total_legislations.extend(legislation_citations)\n",
        "    df_incoming = pd.DataFrame(total_incoming)\n",
        "    df_outgoing = pd.DataFrame(total_outgoing)\n",
        "    df_legislations = pd.DataFrame(total_legislations)\n",
        "    return df_incoming, df_outgoing, df_legislations\n",
        "\n",
        "\n",
        "def citations_multithread_single(big_incoming, big_outgoing, big_legislations, ecli, username, password, current_index,bar):\n",
        "    incoming_df = pd.Series([], dtype='string')\n",
        "    outgoing_df = pd.Series([], dtype='string')\n",
        "    legislations_df = pd.Series([], dtype='string')\n",
        "    for i, ecli in enumerate(ecli):\n",
        "        index = current_index + i\n",
        "        case_citations_incoming, case_citations_outgoing, legislation_citations = find_citations_for_case(\n",
        "            remove_spaces_from_ecli(ecli), case_citations_fieldnames, legislation_citations_fieldnames, username,\n",
        "            password)\n",
        "        if case_citations_incoming:\n",
        "            encoded = json.dumps(case_citations_incoming)\n",
        "            incoming_df[index] = encoded\n",
        "        if case_citations_outgoing:\n",
        "            encoded = json.dumps(case_citations_outgoing)\n",
        "            outgoing_df[index] = encoded\n",
        "        if legislation_citations:\n",
        "            encoded = json.dumps(legislation_citations)\n",
        "            legislations_df[index] = encoded\n",
        "        bar.update(1)\n",
        "    big_incoming.append(incoming_df)\n",
        "    big_outgoing.append(outgoing_df)\n",
        "    big_legislations.append(legislations_df)\n",
        "\n",
        "\n",
        "def add_column_frow_list(data, name, list):\n",
        "    column = pd.Series([], dtype='string')\n",
        "    for l in list:\n",
        "        column = column._append(l)\n",
        "    column.sort_index(inplace=True)\n",
        "    data.insert(1, name, column)\n",
        "\n",
        "\n",
        "def find_citations_for_cases_multithread(dataframe, username, password, threads):\n",
        "    ecli = dataframe['ecli'].dropna().reset_index(drop=True)\n",
        "    length = ecli.size\n",
        "    at_once_threads = int(length / threads)\n",
        "    \n",
        "    global big_incoming, big_outgoing, big_legislations\n",
        "    \n",
        "    big_incoming = []\n",
        "    big_outgoing = []\n",
        "    big_legislations = []\n",
        "    threads = []\n",
        "    bar = tqdm(total=length, colour=\"GREEN\",position=0, leave=True,miniters=int(length/100),maxinterval=10000)\n",
        "    for i in range(0, length, at_once_threads):\n",
        "        curr_ecli = ecli[i:(i + at_once_threads)]\n",
        "        t = threading.Thread(target=citations_multithread_single,\n",
        "                             args=[big_incoming, big_outgoing, big_legislations, curr_ecli, username, password, i,bar])\n",
        "        threads.append(t)\n",
        "    for t in threads:\n",
        "        t.start()\n",
        "    for t in threads:\n",
        "        t.join()\n",
        "    add_column_frow_list(dataframe, 'citations_incoming', big_incoming)\n",
        "    add_column_frow_list(dataframe, 'citations_outgoing', big_outgoing)\n",
        "    add_column_frow_list(dataframe, 'legislations_cited', big_legislations)\n",
        "    return dataframe\n",
        "\n",
        "\n",
        "def add_citations_no_duplicates(already_existing_list, element):\n",
        "    duplicate = False\n",
        "    new_ecli = get_ecli(element)\n",
        "    added_sth_new = True\n",
        "    for stored in already_existing_list:\n",
        "        if stored[target_ecli] == new_ecli:\n",
        "            added_sth_new = False\n",
        "            duplicate = True\n",
        "            break\n",
        "    if not duplicate:\n",
        "        already_existing_list.append({target_ecli: new_ecli,\n",
        "                                      label: element.attrib['label'],\n",
        "                                      type: element.attrib['type'].split('/id/')[1]})\n",
        "    return added_sth_new\n",
        "\n",
        "\n",
        "def add_legislations_no_duplicates(list, element):\n",
        "    duplicate = False\n",
        "    new_legislation = get_legislation_identifier(element)\n",
        "    added_sth_new = True\n",
        "    for legs in list:\n",
        "        if new_legislation == legs:\n",
        "            added_sth_new = False\n",
        "            duplicate = True\n",
        "            break\n",
        "    if not duplicate:\n",
        "        list.append(get_legislation_identifier(element))\n",
        "    return added_sth_new\n",
        "\n",
        "\n",
        "# Main method to execute LIDO API call on the ECLI code of the input case and extract the citations\n",
        "def find_citations_for_case(ecli, case_citations_fieldnames, legislation_citations_fieldnames, username, password):\n",
        "    xml_elements = []\n",
        "    case_law_citations_outgoing = []\n",
        "    legislation_citations = []\n",
        "    case_law_citations_incoming = []\n",
        "    start_page = 0\n",
        "    end_of_pages = False\n",
        "    outgoing = \"uitgaande-links\"\n",
        "    incoming = \"inkomende-links\"\n",
        "\n",
        "    while not end_of_pages:\n",
        "        added_sth_new = False\n",
        "        url = \"{}?id={}&start={}&rows={}&output=xml\".format(LIDO_ENDPOINT, get_lido_id(ecli), start_page, 100)\n",
        "        start_page += 1\n",
        "\n",
        "        xml_text = get_lido_response(url, username, password)\n",
        "        xml_elements.append(etree.fromstring(xml_text.encode('utf8')))\n",
        "\n",
        "        for el in xml_elements:\n",
        "\n",
        "            for sub in list(el.iterchildren('subject')):\n",
        "\n",
        "                for the_citations in sub.iterchildren(outgoing):\n",
        "                    for sub_ref in the_citations.iterchildren():\n",
        "                        if is_case_law(sub_ref):\n",
        "                            added_sth_new = add_citations_no_duplicates(case_law_citations_outgoing, sub_ref)\n",
        "                        elif is_legislation(sub_ref):\n",
        "                            added_sth_new = add_legislations_no_duplicates(legislation_citations, sub_ref)\n",
        "\n",
        "                for the_citations in sub.iterchildren(incoming):\n",
        "                    for sub_ref in the_citations.iterchildren():\n",
        "                        if is_case_law(sub_ref):\n",
        "                            added_sth_new = add_citations_no_duplicates(case_law_citations_incoming, sub_ref)\n",
        "\n",
        "        if not added_sth_new or start_page > 15:\n",
        "            #print(start_page)\n",
        "            end_of_pages = True\n",
        "\n",
        "    # Remove duplicates empties\n",
        "\n",
        "    for item in case_law_citations_incoming:\n",
        "        if item[target_ecli] == \"\":\n",
        "            case_law_citations_incoming.remove(item)\n",
        "    for item in case_law_citations_outgoing:\n",
        "        if item[target_ecli] == \"\":\n",
        "            case_law_citations_outgoing.remove(item)\n",
        "\n",
        "    # Remove input case ECLI (for some reason a case can cite itself...)\n",
        "    for dicts in case_law_citations_incoming:\n",
        "        if dicts[target_ecli] == remove_spaces_from_ecli(ecli):\n",
        "            case_law_citations_incoming.remove(dicts)\n",
        "            break\n",
        "    for dicts in case_law_citations_outgoing:\n",
        "        if dicts[target_ecli] == remove_spaces_from_ecli(ecli):\n",
        "            case_law_citations_outgoing.remove(dicts)\n",
        "            break\n",
        "    if (remove_spaces_from_ecli(ecli) in case_law_citations_incoming):\n",
        "        case_law_citations_incoming.remove(remove_spaces_from_ecli(ecli))\n",
        "\n",
        "    case_law_result_outgoing = extract_results_citations(case_law_citations_outgoing, ecli, case_citations_fieldnames)\n",
        "    case_law_results_incoming = extract_results_citations(case_law_citations_incoming, ecli, case_citations_fieldnames)\n",
        "    legislation_results = extract_results_legislations(legislation_citations, ecli, legislation_citations_fieldnames,\n",
        "                                                       username, password)\n",
        "\n",
        "    return case_law_results_incoming, case_law_result_outgoing, legislation_results\n",
        "\n",
        "\n",
        "def extract_results_citations(list, ecli, fields):\n",
        "    list_of_all_results = []\n",
        "\n",
        "    for case_citation in list:\n",
        "        case_law_result = {key: None for key in fields}\n",
        "        case_law_result[fields[0]] = (remove_spaces_from_ecli(case_citation[target_ecli]))  # Target ECLI\n",
        "        case_law_result[fields[1]] = (case_citation['label'])  # Target ECLI\n",
        "        case_law_result[fields[2]] = (case_citation['type'])  # Target ECLI\n",
        "        list_of_all_results.append(case_law_result)\n",
        "    return list_of_all_results\n",
        "\n",
        "\n",
        "def extract_results_legislations(list, ecli, fields, username, password):\n",
        "    list_of_all_results = []\n",
        "\n",
        "    for leg_citation in list:\n",
        "        legislation_result = {key: None for key in fields}\n",
        "        legislation_result[fields[0]] = (leg_citation)  # Target article\n",
        "        legislation_result[fields[1]] = (get_legislation_webpage(leg_citation))  # Target article webpage\n",
        "        legislation_result[fields[2]] = (\n",
        "            get_legislation_name(leg_citation, username, password))  # pref label == article name\n",
        "        list_of_all_results.append(legislation_result)\n",
        "    return list_of_all_results\n",
        "\n",
        "\n",
        "def get_citations(dataframe=None, username=\"\", password=\"\", threads=1):\n",
        "    if dataframe is None or not username or not password:\n",
        "        print(\"Incorrect arguments passed. Returning...\")\n",
        "        return False\n",
        "    try:\n",
        "        get_lido_response(LIDO_ENDPOINT,username,password)\n",
        "    except:\n",
        "        print('LIDO cannot be accessed with these login details. Returning...')\n",
        "        return False\n",
        "    print('\\n--- START OF RS CITATIONS EXTRACTIONS ---\\n')\n",
        "\n",
        "    # find citations, and save the file incrementally\n",
        "    df = find_citations_for_cases_multithread(dataframe, username, password, threads)\n",
        "\n",
        "    print(\"\\n--- DONE ---\")\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import rechtspraak_citations_extractor as rex_citations\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpZY06r8hLZ9"
      },
      "source": [
        "## Get ecli's HR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pA4WRX1ll8jm"
      },
      "outputs": [],
      "source": [
        "from_values = range(1,44001,1000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "u86sLdtxhqOP",
        "outputId": "55b9550d-3de0-428f-8834-20dde3fbce17"
      },
      "outputs": [],
      "source": [
        "json_rechtspraak = []\n",
        "\n",
        "for from_value in from_values:\n",
        "    new_rechtspraak = get_rechtspraak(max_ecli=1000, sd='1900-01-01', ed='2023-12-31', save_file='n', from_value=from_value, instantie=\"http://standaarden.overheid.nl/owms/terms/Hoge_Raad_der_Nederlanden\")\n",
        "    print(from_value, new_rechtspraak[-1]['id'])\n",
        "    for i in range(0, len(new_rechtspraak)):\n",
        "      json_rechtspraak.append(new_rechtspraak[i])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = save_csv(json_rechtspraak, 'x', 'n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ox-wN0PHpaBQ",
        "outputId": "cedcf3e7-1509-49fe-c6db-121632a559db"
      },
      "outputs": [],
      "source": [
        "# to csv\n",
        "save_csv(json_rechtspraak, 'HR_rechtspraak', 'y')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70i9PMmgCu-X"
      },
      "outputs": [],
      "source": [
        "#to pickle\n",
        "df.to_pickle(\"HR_rechtspraak.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get metadata HR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "get_rechtspraak_metadata(save_file='y', dataframe=df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get citations HR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_part1 = df.iloc[:10000,:]\n",
        "df_part2 = df.iloc[10000:20000,:]\n",
        "df_part3 = df.iloc[20000:30000,:]\n",
        "df_part4 = df.iloc[30000:40000,:]\n",
        "df_part5 = df.iloc[40000:44718,:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df_part1.shape)\n",
        "print(df_part2.shape) \n",
        "print(df_part3.shape)\n",
        "print(df_part4.shape) \n",
        "print(df_part5.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations1 = pd.read_csv(\"data\\HR_rechtspraak_metadata_citations_part1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations1 = df_citations1.drop(df_citations1.columns[0], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations = get_citations(dataframe=df_part1, username='mputs', password='0Opy68ak2dF-tqnx81lJ', threads=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations[\"citations_incoming\"].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations.to_csv(\"data\\HR_rechtspraak_metadata_citations_part1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_part2_1 = df_part2.iloc[:2500,:].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_part2_1 = df_part2.iloc[:2500,:].reset_index(drop=True)\n",
        "df_part2_2 = df_part2.iloc[2500:5000,:].reset_index(drop=True)\n",
        "df_part2_3 = df_part2.iloc[5000:7500,:].reset_index(drop=True)\n",
        "df_part2_4 = df_part2.iloc[7500:10000,:].reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_part2_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df_part2.shape)\n",
        "print(df_part2_1.shape)\n",
        "print(df_part2_2.shape)\n",
        "print(df_part2_3.shape)\n",
        "print(df_part2_4.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations2_1 = get_citations(dataframe=df_part2_1, username='mputs', password='0Opy68ak2dF-tqnx81lJ', threads=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations2_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations2_1[\"citations_outgoing\"].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations2_1.to_csv(\"data\\HR_rechtspraak_metadata_citations_part2_1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations2_2 = get_citations(dataframe=df_part2_2, username='mputs', password='0Opy68ak2dF-tqnx81lJ', threads=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations2_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations2_2[\"legislations_cited\"].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations2_2.to_csv(\"data\\HR_rechtspraak_metadata_citations_part2_2.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations2_3 = get_citations(dataframe=df_part2_3, username='mputs', password='0Opy68ak2dF-tqnx81lJ', threads=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations2_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations2_3.to_csv(\"data\\HR_rechtspraak_metadata_citations_part2_3.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations2_4 = get_citations(dataframe=df_part2_4, username='mputs', password='0Opy68ak2dF-tqnx81lJ', threads=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations2_4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations2_4.to_csv(\"data\\HR_rechtspraak_metadata_citations_part2_4.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list_df_citations2 = [df_citations2_1, df_citations2_2, df_citations2_3, df_citations2_4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations2 = pd.concat(list_df_citations2, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df_citations2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_part2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations2.to_csv(\"data\\HR_rechtspraak_metadata_citations_part2.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_part3_1 = df_part3.iloc[:2500,:].reset_index(drop=True)\n",
        "df_part3_2 = df_part3.iloc[2500:5000,:].reset_index(drop=True)\n",
        "df_part3_3 = df_part3.iloc[5000:7500,:].reset_index(drop=True)\n",
        "df_part3_4 = df_part3.iloc[7500:10000,:].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df_part3.shape)\n",
        "print(df_part3_1.shape)\n",
        "print(df_part3_2.shape)\n",
        "print(df_part3_3.shape)\n",
        "print(df_part3_4.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations3_1 = get_citations(dataframe=df_part3_1, username='mputs', password='0Opy68ak2dF-tqnx81lJ', threads=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations3_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations3_1.to_csv(\"data\\HR_rechtspraak_metadata_citations_part3_1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations3_2 = get_citations(dataframe=df_part3_2, username='mputs', password='0Opy68ak2dF-tqnx81lJ', threads=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations3_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations3_2[\"citations_incoming\"].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations3_2.to_csv(\"data\\HR_rechtspraak_metadata_citations_part3_2.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations3_3 = get_citations(dataframe=df_part3_3, username='mputs', password='0Opy68ak2dF-tqnx81lJ', threads=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations3_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations3_3[\"citations_incoming\"].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations3_3.to_csv(\"data\\HR_rechtspraak_metadata_citations_part3_3.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations3_4 = get_citations(dataframe=df_part3_4, username='mputs', password='0Opy68ak2dF-tqnx81lJ', threads=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations3_4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations3_4[\"citations_incoming\"].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations3_4.to_csv(\"data\\HR_rechtspraak_metadata_citations_part3_4.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list_df_citations3 = [df_citations3_1, df_citations3_2, df_citations3_3, df_citations3_4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations3 = pd.concat(list_df_citations3, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df_citations3.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_part3.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations3.to_csv(\"data\\HR_rechtspraak_metadata_citations_part3.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_part4_1 = df_part4.iloc[:2500,:].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_part4_1 = df_part4.iloc[:2500,:].reset_index(drop=True)\n",
        "df_part4_2 = df_part4.iloc[2500:5000,:].reset_index(drop=True)\n",
        "df_part4_3 = df_part4.iloc[5000:7500,:].reset_index(drop=True)\n",
        "df_part4_4 = df_part4.iloc[7500:10000,:].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df_part4.shape)\n",
        "print(df_part4_1.shape)\n",
        "print(df_part4_2.shape)\n",
        "print(df_part4_3.shape)\n",
        "print(df_part4_4.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations4_1 = get_citations(dataframe=df_part4_1, username='mputs', password='0Opy68ak2dF-tqnx81lJ', threads=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations4_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations4_1.to_csv(\"data\\HR_rechtspraak_metadata_citations_part4_1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations4_2 = get_citations(dataframe=df_part4_2, username='mputs', password='0Opy68ak2dF-tqnx81lJ', threads=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations4_2 = df_part4_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations4_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations4_2.to_csv(\"data\\HR_rechtspraak_metadata_citations_part4_2.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations4_3 = get_citations(dataframe=df_part4_3, username='mputs', password='0Opy68ak2dF-tqnx81lJ', threads=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations4_3 = df_part4_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations4_3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations4_3.to_csv(\"data\\HR_rechtspraak_metadata_citations_part4_3.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations4_4 = get_citations(dataframe=df_part4_4, username='mputs', password='0Opy68ak2dF-tqnx81lJ', threads=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations4_4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_part4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_part4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations4_4.to_csv(\"data\\HR_rechtspraak_metadata_citations_part4_4.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list_df_citations4 = [df_citations4_1, df_citations4_2, df_citations4_3, df_citations4_4]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations4 = pd.concat(list_df_citations4, ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df_citations4.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_part4.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations4.to_csv(\"data\\HR_rechtspraak_metadata_citations_part4.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_part5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_part5_1 = df_part5.iloc[:2500,:].reset_index(drop=True)\n",
        "df_part5_2 = df_part5.iloc[2500:4717,:].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(df_part5.shape)\n",
        "print(df_part5_1.shape)\n",
        "print(df_part5_2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_part5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_part5_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations5_1 = get_citations(dataframe=df_part5_1, username='mputs', password='0Opy68ak2dF-tqnx81lJ', threads=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations5_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations5_1.to_csv(\"data\\HR_rechtspraak_metadata_citations_part5_1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations5_2 = get_citations(dataframe=df_part5_2, username='mputs', password='0Opy68ak2dF-tqnx81lJ', threads=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations5_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations5_2.to_csv(\"data\\HR_rechtspraak_metadata_citations_part5_2.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list_df_citations5 = [df_citations5_1, df_citations5_2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations5 = pd.concat(list_df_citations5, ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_part5.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations5.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "list_df_full = [df_citations1, df_citations2, df_citations3, df_citations4, df_citations5]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations_full = pd.concat(list_df_full, ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations_full"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations_full.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations_full.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations_full[\"ecli\"].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations_full.to_csv(\"data\\HR_rechtspraak_metadata_citations_full.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_citations_full.to_pickle(\"data\\HR_rechtspraak_metadata_citations_full.pkl\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
